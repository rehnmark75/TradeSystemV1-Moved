# ===== MAIN STRATEGY FILE =====
# core/strategies/bb_supertrend_strategy.py
"""
ðŸ”¥ FOREX-OPTIMIZED Bollinger Bands + Supertrend Strategy Implementation - MODULAR ARCHITECTURE
ðŸ—ï¸ MODULAR: Clean separation of concerns with focused helper modules
ðŸŽ¯ MAINTAINABLE: Easy to understand, modify, and extend
âš¡ PERFORMANCE: Intelligent caching and optimizations
ðŸ§  SMART: Enhanced Signal Validator integration with forex market context

REFACTORING COMPLETE: Main strategy now focuses on coordination while
specialized modules handle specific responsibilities:
- BBForexOptimizer: Forex-specific calculations and optimizations
- BBValidator: Signal validation and confidence calculation  
- BBCache: Performance caching and optimization
- BBSignalDetector: Core signal detection algorithms
- BBDataHelper: Data preparation and enhancement

ðŸ†• ENHANCED FEATURES:
- Squeezeâ†’Expansion detection with band walk confirmation
- Enhanced configuration system with pre-built setups
- Improved signal quality and market regime awareness
- Backward compatibility maintained

This maintains 100% backward compatibility while dramatically improving maintainability!
"""

import pandas as pd
import numpy as np
from typing import Dict, Optional, List
import logging
from datetime import datetime

from .base_strategy import BaseStrategy
from ..detection.price_adjuster import PriceAdjuster
from ..detection.enhanced_signal_validator import EnhancedSignalValidator
from .helpers.bb_reversal_detector import BBReversalDetector


# Import our new modular helpers
from .helpers.bb_forex_optimizer import BBForexOptimizer
from .helpers.bb_validator import BBValidator
from .helpers.bb_cache import BBCache
from .helpers.bb_signal_detector import BBSignalDetector
from .helpers.bb_data_helper import BBDataHelper

# ðŸ†• NEW: Import enhanced configuration system
try:
    from .helpers.bb_enhanced_config import BBConfigFactory, BBEnhancedConfig, integrate_with_main_config
    ENHANCED_CONFIG_AVAILABLE = True
except ImportError as e:
    logging.getLogger(__name__).warning(f"Enhanced BB config not available: {e}")
    ENHANCED_CONFIG_AVAILABLE = False
    # Create dummy classes to prevent errors
    class BBConfigFactory:
        @staticmethod
        def fx15m_default(symbol=None):
            return None
        @staticmethod
        def get_config_for_timeframe(timeframe, mode='default', symbol=None):
            return None
    
    class BBEnhancedConfig:
        def to_dict(self):
            return {}

try:
    import config
except ImportError:
    from forex_scanner import config


class BollingerSupertrendStrategy(BaseStrategy):
    """
    ðŸ”¥ FOREX OPTIMIZED & MODULAR: Bollinger Bands + Supertrend strategy implementation
    
    Now organized with clean separation of concerns:
    - Main class handles coordination and public interface
    - Helper modules handle specialized functionality
    - 100% backward compatibility maintained
    - Dramatically improved maintainability and testability
    
    ðŸ†• ENHANCED FEATURES:
    - Enhanced configuration system with pre-built setups
    - Squeezeâ†’Expansion detection with band walk confirmation
    - Improved signal detection algorithms
    - Market regime awareness and adaptive behavior
    """
    
    def __init__(self, bb_config_name: str = 'default', data_fetcher=None):
        super().__init__('bollinger_supertrend')
        
        # Initialize core components
        self.price_adjuster = PriceAdjuster()
        self.data_fetcher = data_fetcher
        self.config_name = bb_config_name
        
        # ðŸ†• NEW: Initialize enhanced configuration system
        self.enhanced_config = None
        self.use_enhanced_features = False
        
        if ENHANCED_CONFIG_AVAILABLE:
            self._initialize_enhanced_configuration()
        
        # ðŸ—ï¸ MODULAR: Initialize specialized helper modules
        self.forex_optimizer = BBForexOptimizer(logger=self.logger, config_name=bb_config_name)
        self.validator = BBValidator(logger=self.logger, forex_optimizer=self.forex_optimizer)
        self.cache = BBCache(logger=self.logger)
        self.data_helper = BBDataHelper(logger=self.logger, forex_optimizer=self.forex_optimizer)
        self.reversal_detector = BBReversalDetector(logger=self.logger)
        
        # Initialize signal detector with injected dependencies
        self.signal_detector = BBSignalDetector(
            logger=self.logger,
            forex_optimizer=self.forex_optimizer,
            validator=self.validator
        )
        
        # ðŸ†• NEW: Apply enhanced configuration to signal detector if available
        if self.enhanced_config and hasattr(self.signal_detector, 'update_config'):
            try:
                self.signal_detector.update_config(self.enhanced_config.to_dict())
                self.logger.info(f"ðŸ†• Enhanced configuration applied to signal detector")
            except Exception as e:
                self.logger.warning(f"Failed to apply enhanced config to signal detector: {e}")
        
        # ðŸ§  Initialize Enhanced Signal Validator
        self.enhanced_validator = EnhancedSignalValidator(logger=self.logger)
        
        # ðŸ†• NEW: Initialize Multi-Timeframe Analyzer
        self.multi_timeframe_analyzer = None
        if self.data_fetcher:
            try:
                from analysis.multi_timeframe import MultiTimeframeAnalyzer
                self.multi_timeframe_analyzer = MultiTimeframeAnalyzer(data_fetcher=self.data_fetcher)
                self.logger.info("ðŸ”„ Multi-timeframe analyzer initialized for BB+SuperTrend strategy")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Could not initialize multi-timeframe analyzer: {e}")
        
        # Get configuration from forex optimizer
        self.bb_config = self.forex_optimizer.get_bb_config()
        
        # ðŸ†• NEW: Merge enhanced configuration with legacy bb_config
        if self.enhanced_config:
            self._merge_enhanced_config_with_legacy()
        
        # Set minimum bars needed
        self.min_bars = max(
            self.bb_config['bb_period'],
            self.bb_config['supertrend_period']
        ) + 5
        
        self.logger.info(f"ðŸ”¥ MODULAR BB+Supertrend Strategy initialized:")
        self.logger.info(f"  ðŸ“Š Config: {bb_config_name}")
        if self.enhanced_config:
            self.logger.info(f"  ðŸ†• Enhanced Features: ENABLED")
            self.logger.info(f"     - Squeezeâ†’Expansion: {self.enhanced_config.enable_squeeze_expansion}")
            self.logger.info(f"     - Band Walk: {self.enhanced_config.enable_band_walk_confirmation}")
            self.logger.info(f"     - Trend Detection: {self.enhanced_config.trend_detection}")
        self.logger.info(f"  ðŸ“ˆ BB Period: {self.bb_config['bb_period']}, Std Dev: {self.bb_config['bb_std_dev']}")
        self.logger.info(f"  ðŸ“‰ Supertrend: Period {self.bb_config['supertrend_period']}, Multiplier {self.bb_config['supertrend_multiplier']}")
        self.logger.info(f"  ðŸŽ¯ Base Confidence: {self.bb_config['base_confidence']:.1%}")
        self.logger.info(f"  ðŸ—ï¸ MODULAR: All helper modules initialized")
        self.logger.info(f"  ðŸ†• EMA200 Filter Bypass: ENABLED (Mean Reversion Strategy)")
        self.logger.info(f"  ðŸ”„ Multi-timeframe Analysis: {'ENABLED' if self.multi_timeframe_analyzer else 'DISABLED'}")
        
        # ðŸ” DEBUG: Forex optimizer cache initialization check
        if self.forex_optimizer:
            self.logger.debug("ðŸ” FOREX OPTIMIZER INITIALIZATION DEBUG:")
            self.logger.debug(f"  Type: {type(self.forex_optimizer)}")
            self.logger.debug(f"  Has _cache: {hasattr(self.forex_optimizer, '_cache')}")
            self.logger.debug(f"  Has get_cache_stats: {hasattr(self.forex_optimizer, 'get_cache_stats')}")
            self.logger.debug(f"  Has clear_cache: {hasattr(self.forex_optimizer, 'clear_cache')}")
            
            # Try to get initial cache stats
            try:
                initial_cache_stats = self.forex_optimizer.get_cache_stats()
                self.logger.debug(f"  Initial cache stats: {initial_cache_stats}")
            except Exception as e:
                self.logger.debug(f"  âŒ Initial cache stats failed: {e}")
                
            # Test if forex optimizer cache is working at all
            try:
                test_epic = "CS.D.EURUSD.MINI.IP"
                test_pair_type = self.forex_optimizer.get_forex_pair_type(test_epic)
                self.logger.debug(f"  âœ… Test pair type call: {test_pair_type}")
                
                # Check cache after test call
                post_test_cache_stats = self.forex_optimizer.get_cache_stats()
                self.logger.debug(f"  Cache after test: {post_test_cache_stats}")
            except Exception as e:
                self.logger.debug(f"  âŒ Test forex optimizer call failed: {e}")
        else:
            self.logger.debug("ðŸ” No forex optimizer to debug")

    def _initialize_enhanced_configuration(self):
        """
        ðŸ†• NEW: Initialize enhanced configuration system
        """
        try:
            # Check if enhanced config is enabled in main config
            use_enhanced_config = getattr(config, 'BB_USE_ENHANCED_CONFIG', False)
            enhanced_mode = getattr(config, 'BB_ENHANCED_MODE', 'default')
            enhanced_timeframe = getattr(config, 'BB_ENHANCED_TIMEFRAME', '15m')
            enhanced_symbol = getattr(config, 'BB_ENHANCED_SYMBOL', None)
            
            if use_enhanced_config:
                self.logger.info(f"ðŸ†• Initializing enhanced BB configuration: {enhanced_mode} mode for {enhanced_timeframe}")
                
                # Create enhanced configuration
                if self.config_name == 'conservative':
                    self.enhanced_config = BBConfigFactory.fx15m_conservative(enhanced_symbol)
                elif self.config_name == 'aggressive':
                    self.enhanced_config = BBConfigFactory.fx15m_aggressive(enhanced_symbol)
                else:
                    # Use factory to get config based on timeframe and mode
                    self.enhanced_config = BBConfigFactory.get_config_for_timeframe(
                        timeframe=enhanced_timeframe,
                        mode=enhanced_mode,
                        symbol=enhanced_symbol
                    )
                
                if self.enhanced_config:
                    # Validate configuration
                    if self.enhanced_config.validate():
                        self.use_enhanced_features = True
                        self.logger.info(f"âœ… Enhanced configuration validated successfully")
                        
                        # Optionally integrate with main config
                        if getattr(config, 'BB_INTEGRATE_ENHANCED_CONFIG', True):
                            success = integrate_with_main_config(config, self.enhanced_config)
                            if success:
                                self.logger.info(f"âœ… Enhanced config integrated with main config")
                            else:
                                self.logger.warning(f"âš ï¸ Failed to integrate enhanced config with main config")
                    else:
                        self.logger.error(f"âŒ Enhanced configuration validation failed")
                        self.enhanced_config = None
                else:
                    self.logger.warning(f"âš ï¸ Failed to create enhanced configuration")
            else:
                self.logger.debug(f"Enhanced BB configuration disabled in main config")
                
        except Exception as e:
            self.logger.error(f"âŒ Enhanced configuration initialization failed: {e}")
            self.enhanced_config = None
            self.use_enhanced_features = False

    def _merge_enhanced_config_with_legacy(self):
        """
        ðŸ†• NEW: Merge enhanced configuration with legacy bb_config
        """
        try:
            if not self.enhanced_config:
                return
            
            enhanced_dict = self.enhanced_config.to_dict()
            
            # Map enhanced config keys to legacy bb_config keys
            config_mapping = {
                'bb_length': 'bb_period',
                'bb_std': 'bb_std_dev',
                'st_atr_length': 'supertrend_period',
                'st_multiplier': 'supertrend_multiplier',
                'atr_length': 'atr_period',
                'min_confidence_threshold': 'base_confidence'
            }
            
            # Update legacy config with enhanced values
            for enhanced_key, legacy_key in config_mapping.items():
                if enhanced_key in enhanced_dict and legacy_key in self.bb_config:
                    old_value = self.bb_config[legacy_key]
                    new_value = enhanced_dict[enhanced_key]
                    self.bb_config[legacy_key] = new_value
                    self.logger.debug(f"ðŸ”„ Updated {legacy_key}: {old_value} â†’ {new_value}")
            
            # Add new enhanced config keys directly
            enhanced_only_keys = [
                'squeeze_ema_length', 'squeeze_factor', 'expansion_factor',
                'band_walk_n', 'band_buffer_atr_mult', 'trend_detection',
                'require_supertrend_agreement', 'max_spread_pips', 'min_atr_pips',
                'range_sl_atr_mult', 'trend_trail_atr_mult', 'range_tp_offset_pips',
                'session_start_hour', 'session_end_hour', 'enter_on_close'
            ]
            
            for key in enhanced_only_keys:
                if key in enhanced_dict:
                    self.bb_config[key] = enhanced_dict[key]
                    self.logger.debug(f"ðŸ†• Added enhanced config: {key} = {enhanced_dict[key]}")
            
            self.logger.info(f"âœ… Enhanced configuration merged with legacy bb_config")
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to merge enhanced config with legacy: {e}")

    def get_enhanced_config_info(self) -> Dict:
        """
        ðŸ†• NEW: Get information about enhanced configuration
        """
        if not self.enhanced_config:
            return {
                'enhanced_config_available': ENHANCED_CONFIG_AVAILABLE,
                'enhanced_config_enabled': False,
                'enhanced_features_active': False,
                'config_type': 'legacy_only'
            }
        
        return {
            'enhanced_config_available': ENHANCED_CONFIG_AVAILABLE,
            'enhanced_config_enabled': True,
            'enhanced_features_active': self.use_enhanced_features,
            'config_type': self.config_name,
            'squeeze_expansion_enabled': self.enhanced_config.enable_squeeze_expansion,
            'band_walk_enabled': self.enhanced_config.enable_band_walk_confirmation,
            'trend_detection_mode': self.enhanced_config.trend_detection,
            'session_filtering_enabled': bool(self.enhanced_config.session_start_hour),
            'configuration_summary': {
                'bb_length': self.enhanced_config.bb_length,
                'bb_std': self.enhanced_config.bb_std,
                'squeeze_factor': self.enhanced_config.squeeze_factor,
                'expansion_factor': self.enhanced_config.expansion_factor,
                'band_walk_n': self.enhanced_config.band_walk_n,
                'min_confidence': self.enhanced_config.min_confidence_threshold
            }
        }

    def update_enhanced_config(self, new_config_dict: Dict) -> bool:
        """
        ðŸ†• NEW: Update enhanced configuration at runtime
        """
        try:
            if not self.enhanced_config:
                self.logger.warning("No enhanced configuration to update")
                return False
            
            # Update enhanced config
            for key, value in new_config_dict.items():
                if hasattr(self.enhanced_config, key):
                    old_value = getattr(self.enhanced_config, key)
                    setattr(self.enhanced_config, key, value)
                    self.logger.info(f"ðŸ”„ Updated enhanced config {key}: {old_value} â†’ {value}")
            
            # Validate updated config
            if not self.enhanced_config.validate():
                self.logger.error("âŒ Updated enhanced configuration failed validation")
                return False
            
            # Re-merge with legacy config
            self._merge_enhanced_config_with_legacy()
            
            # Update signal detector config if it supports it
            if hasattr(self.signal_detector, 'update_config'):
                self.signal_detector.update_config(self.enhanced_config.to_dict())
                self.logger.info("âœ… Signal detector configuration updated")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to update enhanced configuration: {e}")
            return False

    def validate_modular_integration(self) -> bool:
        """
        âœ… Validate that all modular components are properly initialized
        """
        try:
            components = {
                'forex_optimizer': self.forex_optimizer,
                'validator': self.validator,
                'cache': self.cache,
                'data_helper': self.data_helper,
                'signal_detector': self.signal_detector,
                'enhanced_validator': self.enhanced_validator
            }
            
            missing = [name for name, component in components.items() if component is None]
            
            if missing:
                self.logger.error(f"âŒ Missing modular components: {missing}")
                return False
            
            # Test basic functionality of each component
            test_results = []
            
            # Test forex optimizer
            try:
                config_test = self.forex_optimizer.get_bb_config()
                test_results.append(f"âœ… forex_optimizer: Config loaded with {len(config_test)} parameters")
            except Exception as e:
                test_results.append(f"âŒ forex_optimizer: {e}")
                return False
            
            # Test cache
            try:
                cache_stats = self.cache.get_cache_stats()
                test_results.append(f"âœ… cache: Statistics available with {len(cache_stats)} metrics")
            except Exception as e:
                test_results.append(f"âŒ cache: {e}")
                return False
            
            # ðŸ†• NEW: Test enhanced configuration
            if self.enhanced_config:
                try:
                    config_info = self.get_enhanced_config_info()
                    test_results.append(f"âœ… enhanced_config: {config_info['config_type']} mode active")
                except Exception as e:
                    test_results.append(f"âš ï¸ enhanced_config: {e}")
            else:
                test_results.append(f"â„¹ï¸ enhanced_config: Not enabled (using legacy config)")
            
            self.logger.info("ðŸ—ï¸ MODULAR INTEGRATION VALIDATION:")
            for result in test_results:
                self.logger.info(f"  {result}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Modular integration validation failed: {e}")
            return False

    def get_required_indicators(self) -> List[str]:
        """Required indicators for BB+Supertrend strategy"""
        required = [
            'close', 'high', 'low',
            'bb_upper', 'bb_middle', 'bb_lower',
            'supertrend', 'supertrend_direction',
            'atr',
            'volume', 'ltv'
        ]
        
        # ðŸ†• NEW: Add enhanced indicators if squeeze/expansion is enabled
        if self.enhanced_config and self.enhanced_config.enable_squeeze_expansion:
            required.extend(['bb_width', 'bbw_ema'])
        
        return required
    
    def detect_signal(
        self, 
        df: pd.DataFrame, 
        epic: str, 
        spread_pips: float = 1.5,
        timeframe: str = '5m'
    ) -> Optional[Dict]:
        """
        ðŸ§  MODULAR: Main signal detection using all helper modules + multi-timeframe analysis
        ðŸš€ ENHANCED: Now with proper cache integration and debugging
        ðŸ†• NEW: Enhanced with squeezeâ†’expansion and band walk confirmation when enabled
        """
        self.logger.debug(f"ðŸ” MODULAR BB+Supertrend signal detection for {epic}")
        
        try:
            # ðŸ” DEBUG: Cache integration check
            if hasattr(self, 'cache') and self.cache:
                cache_stats_before = self.cache.get_cache_stats()
                self.logger.debug(f"ðŸš€ Cache status before signal: {cache_stats_before['cache_hits']} hits, {cache_stats_before['cache_misses']} misses")
            
            # 1. Validate input data using data helper
            if not self.data_helper.validate_input_data(df, epic, self.min_bars):
                return None
            
            # 2. Ensure all indicators using data helper
            df_enhanced = self.data_helper.ensure_bb_indicators(df)
            
            # ðŸ†• NEW: Add enhanced indicators if using enhanced configuration
            if self.enhanced_config and self.enhanced_config.enable_squeeze_expansion:
                df_enhanced = self._ensure_enhanced_indicators(df_enhanced)
            
            # 3. Apply price adjustments if needed
            if getattr(config, 'USE_BID_ADJUSTMENT', False):
                df_adjusted = self.price_adjuster.adjust_bid_to_mid_prices(df_enhanced, spread_pips)
            else:
                df_adjusted = df_enhanced
            
            # 4. Get latest data points
            current = df_adjusted.iloc[-1]
            previous = df_adjusted.iloc[-2]
            
            # ðŸš€ NEW: Force cache usage test to ensure it's working
            try:
                if hasattr(self, 'cache') and self.cache:
                    # Test cache methods directly (don't access internal cache)
                    efficiency_cached = self.cache.calculate_efficiency_ratio_cached(current, previous, epic, timeframe)
                    regime_cached = self.cache.detect_market_regime_cached(current, df_adjusted, epic, timeframe)
                    
                    self.logger.debug(f"ðŸš€ Cache test: efficiency={efficiency_cached:.3f}, regime={regime_cached}")
                    
                    # ðŸ” DEBUG: Extensive forex optimizer cache testing
                    if hasattr(self, 'forex_optimizer') and self.forex_optimizer:
                        self.logger.debug("ðŸ” FOREX OPTIMIZER CACHE DEBUG:")
                        self.logger.debug(f"  Forex optimizer type: {type(self.forex_optimizer)}")
                        self.logger.debug(f"  Has cache attribute: {hasattr(self.forex_optimizer, '_cache')}")
                        
                        # Test each forex optimizer method individually
                        try:
                            pair_type = self.forex_optimizer.get_forex_pair_type(epic)
                            self.logger.debug(f"  âœ… Pair type: {pair_type}")
                        except Exception as e:
                            self.logger.debug(f"  âŒ Pair type failed: {e}")
                        
                        try:
                            market_regime_fo = self.forex_optimizer.detect_forex_market_regime(current)
                            self.logger.debug(f"  âœ… Market regime: {market_regime_fo}")
                        except Exception as e:
                            self.logger.debug(f"  âŒ Market regime failed: {e}")
                        
                        try:
                            efficiency_fo = self.forex_optimizer.calculate_forex_efficiency_ratio(current, previous)
                            self.logger.debug(f"  âœ… Efficiency ratio: {efficiency_fo:.3f}")
                        except Exception as e:
                            self.logger.debug(f"  âŒ Efficiency ratio failed: {e}")
                        
                        try:
                            volatility_assessment = self.forex_optimizer.assess_bb_volatility(current)
                            self.logger.debug(f"  âœ… Volatility assessment: {volatility_assessment}")
                        except Exception as e:
                            self.logger.debug(f"  âŒ Volatility assessment failed: {e}")
                        
                        # Check forex optimizer cache stats
                        try:
                            fo_cache_stats = self.forex_optimizer.get_cache_stats()
                            self.logger.debug(f"  ðŸ“Š FO Cache Stats: {fo_cache_stats}")
                        except Exception as e:
                            self.logger.debug(f"  âŒ FO Cache stats failed: {e}")
                        
                        # Test cache clearing
                        try:
                            self.forex_optimizer.clear_cache()
                            self.logger.debug(f"  ðŸ§¹ FO Cache cleared successfully")
                        except Exception as e:
                            self.logger.debug(f"  âŒ FO Cache clear failed: {e}")
                        
            except Exception as cache_error:
                self.logger.debug(f"âš ï¸ Cache test failed: {cache_error}")  # Don't show hash, show actual error
            
            # 5. Use signal detector to identify potential signals
            signal_type = self.signal_detector.detect_bb_supertrend_signal(current, previous)
            
            if not signal_type:
                return None
            
            # ðŸ†• NEW: Step 5.5 - Reversal Quality Analysis
            bb_position = self._calculate_bb_position(current)
            reversal_analysis = self.reversal_detector.detect_reversal_quality(
                df_adjusted, signal_type, bb_position
            )

            # Check if reversal quality is sufficient
            if not reversal_analysis['should_trade']:
                self.logger.debug(f"ðŸš« {signal_type} signal REJECTED due to poor reversal quality")
                self.logger.debug(f"   Quality score: {reversal_analysis['quality_score']:.2f}")
                self.logger.debug(f"   Quality level: {reversal_analysis['quality_level']}")
                self.logger.debug(f"   Factors: {reversal_analysis['quality_factors']}")
                return None

            self.logger.info(f"âœ… {signal_type} reversal quality approved:")
            self.logger.info(f"   Quality score: {reversal_analysis['quality_score']:.2f}")
            self.logger.info(f"   Expected win rate: {reversal_analysis['expected_win_rate']:.1%}")
            self.logger.info(f"   Risk level: {reversal_analysis['risk_level']}")
                
            # 6. ðŸ”„ Multi-timeframe confirmation analysis (uses cache internally)
            mtf_analysis = self._perform_multi_timeframe_analysis(epic, signal_type, timeframe)
            
            # 7. Use validator to validate signal with cached calculations + MTF analysis
            should_trade, confidence_score, reason = self.validator.validate_bb_supertrend_signal(
                current, previous, signal_type, epic, timeframe
            )
            
            # ðŸš€ ENHANCED: Use cached calculations for efficiency ratio and market regime
            try:
                if hasattr(self, 'cache') and self.cache:
                    # Get cached efficiency ratio for validation enhancement
                    efficiency_ratio = self.cache.calculate_efficiency_ratio_cached(current, previous, epic, timeframe)
                    market_regime = self.cache.detect_market_regime_cached(current, df_adjusted, epic, timeframe)
                    
                    # Apply additional cached calculation benefits to confidence
                    if efficiency_ratio > 0.3:  # Good efficiency
                        confidence_score += 0.02  # 2% bonus for good market efficiency
                        reason += f" | High efficiency (+2%): {efficiency_ratio:.2f}"
                    
                    if market_regime in ['volatile', 'ranging']:  # Good for BB strategy
                        confidence_score += 0.03  # 3% bonus for favorable market regime
                        reason += f" | Favorable regime (+3%): {market_regime}"
                        
            except Exception as cached_calc_error:
                self.logger.debug(f"Cached calculations failed: {cached_calc_error}")
            
            # ðŸ†• NEW: Apply enhanced configuration confidence adjustments
            if self.enhanced_config:
                confidence_score, reason = self._apply_enhanced_config_adjustments(
                    confidence_score, reason, current, previous, signal_type
                )
            
            # 8. ðŸ”„ Apply multi-timeframe confidence adjustments
            if mtf_analysis and should_trade:
                confidence_score, reason = self._apply_mtf_confidence_adjustments(
                    confidence_score, reason, mtf_analysis, signal_type
                )
                
                # Re-check if signal is still valid after MTF adjustments
                min_confidence = getattr(config, 'MIN_CONFIDENCE', 0.60)
                if confidence_score < min_confidence:
                    should_trade = False
                    reason += f" | MTF adjusted confidence {confidence_score:.1%} below threshold {min_confidence:.1%}"
            
            if not should_trade:
                self.logger.debug(f"ðŸš« BB+SuperTrend {signal_type} signal REJECTED: {reason}")
                return None
            
            # 9. Create comprehensive signal using data helper
            signal = self.data_helper.create_enhanced_signal(
                signal_type, epic, timeframe, current, previous, 
                confidence_score, spread_pips, reason
            )

            # ðŸ†• NEW: Add reversal quality data to signal
            signal['reversal_analysis'] = reversal_analysis
            signal['quality_score'] = reversal_analysis['quality_score']
            signal['quality_level'] = reversal_analysis['quality_level']
            signal['expected_win_rate'] = reversal_analysis['expected_win_rate']
            signal['risk_level'] = reversal_analysis['risk_level']
            signal['reversal_strength'] = reversal_analysis['reversal_strength']

            # Enhance confidence score based on reversal quality
            quality_bonus = (reversal_analysis['quality_score'] - 0.5) * 0.2  # Up to Â±10% adjustment
            confidence_score += quality_bonus
            confidence_score = max(0.15, min(confidence_score, 0.95))  # Clamp to bounds
            signal['confidence_score'] = confidence_score
            
            # Update reason with quality info
            signal['reason'] += f" | Reversal quality: {reversal_analysis['quality_level']} ({reversal_analysis['quality_score']:.2f})"

            
            # 10. ðŸ”„ Add multi-timeframe analysis to signal
            if mtf_analysis:
                signal['multi_timeframe_analysis'] = mtf_analysis
                signal['mtf_confluence_score'] = mtf_analysis.get('confluence_score', 0)
                signal['mtf_agreement_level'] = mtf_analysis.get('agreement_level', 'unknown')
                signal['higher_timeframe_bias'] = mtf_analysis.get('higher_timeframe_bias', 'neutral')
            
            # ðŸ†• NEW: Add enhanced configuration information to signal
            if self.enhanced_config:
                signal['enhanced_features'] = {
                    'squeeze_expansion_detected': self._detect_squeeze_expansion(current, previous),
                    'band_walk_confirmed': self._detect_band_walk_confirmation(current),
                    'trend_mode': self._determine_trend_mode(current),
                    'enhanced_config_active': True,
                    'config_type': self.config_name
                }
            
            # ðŸš€ NEW: Add cache performance data to signal
            if hasattr(self, 'cache') and self.cache:
                try:
                    cache_stats_after = self.cache.get_cache_stats()
                    signal['cache_performance'] = {
                        'cache_hits': cache_stats_after['cache_hits'],
                        'cache_misses': cache_stats_after['cache_misses'],
                        'hit_ratio': cache_stats_after['hit_ratio'],
                        'cached_entries_total': cache_stats_after.get('cached_entries', {}).get('total', 0)
                    }
                    
                    # Calculate cache usage for this signal (safely)
                    try:
                        cache_usage_this_signal = cache_stats_after['cache_hits'] - cache_stats_before['cache_hits']
                        if cache_usage_this_signal > 0:
                            self.logger.debug(f"ðŸš€ Cache usage for this signal: {cache_usage_this_signal} hits")
                    except Exception:
                        pass  # Don't fail if we can't calculate usage difference
                    
                except Exception as cache_stats_error:
                    self.logger.debug(f"Cache stats collection failed: {cache_stats_error}")
            
            self.logger.info(f"âœ… MODULAR BB+SuperTrend {signal_type} signal APPROVED for {epic}")
            self.logger.info(f"   ðŸŽ¯ Confidence: {confidence_score:.1%}")
            self.logger.info(f"   ðŸ“ Reason: {reason}")
            self.logger.info(f"   ðŸ†• EMA200 Filter Bypass: ACTIVE (Mean Reversion)")
            if self.enhanced_config:
                self.logger.info(f"   ðŸ†• Enhanced Features: ACTIVE ({self.config_name} mode)")
            if mtf_analysis:
                self.logger.info(f"   ðŸ”„ MTF Confluence: {mtf_analysis.get('confluence_score', 0):.1%} "
                               f"({mtf_analysis.get('agreement_level', 'unknown')})")
            
            # ðŸš€ Log cache performance for this signal
            if hasattr(self, 'cache') and self.cache:
                try:
                    final_cache_stats = self.cache.get_cache_stats()
                    self.logger.info(f"   ðŸš€ Cache Performance: {final_cache_stats['hit_ratio']:.1%} hit ratio "
                                   f"({final_cache_stats['cache_hits']} hits, {final_cache_stats['cache_misses']} misses)")
                except Exception:
                    pass
            
            return signal
            
        except Exception as e:
            self.logger.error(f"âŒ MODULAR BB+Supertrend signal detection error for {epic}: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None

    def _ensure_enhanced_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ðŸ†• NEW: Ensure enhanced indicators are calculated for squeeze/expansion detection
        """
        try:
            if not self.enhanced_config:
                return df
            
            df_enhanced = df.copy()
            
            # Calculate BB width if not present
            if 'bb_width' not in df_enhanced.columns:
                if all(col in df_enhanced.columns for col in ['bb_upper', 'bb_lower', 'bb_middle']):
                    bb_width = df_enhanced['bb_upper'] - df_enhanced['bb_lower']
                    # Normalize by middle band
                    df_enhanced['bb_width'] = bb_width / df_enhanced['bb_middle'].replace(0, np.nan)
                    self.logger.debug("ðŸ“Š Calculated BB width indicator")
            
            # Calculate BB width EMA if not present
            if 'bbw_ema' not in df_enhanced.columns and 'bb_width' in df_enhanced.columns:
                squeeze_length = self.enhanced_config.squeeze_ema_length
                df_enhanced['bbw_ema'] = df_enhanced['bb_width'].ewm(span=squeeze_length, adjust=False).mean()
                self.logger.debug(f"ðŸ“Š Calculated BB width EMA ({squeeze_length} periods)")
            
            # Calculate squeeze and expansion signals
            if all(col in df_enhanced.columns for col in ['bb_width', 'bbw_ema']):
                squeeze_factor = self.enhanced_config.squeeze_factor
                expansion_factor = self.enhanced_config.expansion_factor
                
                df_enhanced['squeeze'] = df_enhanced['bb_width'] < (df_enhanced['bbw_ema'] * squeeze_factor)
                df_enhanced['expansion_now'] = df_enhanced['bb_width'] > (df_enhanced['bbw_ema'] * expansion_factor)
                df_enhanced['s2e'] = df_enhanced['squeeze'].shift(1).fillna(False) & df_enhanced['expansion_now']
                
                self.logger.debug(f"ðŸ“Š Calculated squeeze/expansion signals (factors: {squeeze_factor}/{expansion_factor})")
            
            return df_enhanced
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to ensure enhanced indicators: {e}")
            return df

    def _apply_enhanced_config_adjustments(
        self, 
        confidence_score: float, 
        reason: str, 
        current: pd.Series, 
        previous: pd.Series, 
        signal_type: str
    ) -> tuple[float, str]:
        """
        ðŸ†• NEW: Apply enhanced configuration-based confidence adjustments
        """
        try:
            if not self.enhanced_config:
                return confidence_score, reason
            
            adjusted_confidence = confidence_score
            enhanced_reasons = []
            
            # 1. Squeezeâ†’Expansion bonus
            if self.enhanced_config.enable_squeeze_expansion:
                s2e_detected = self._detect_squeeze_expansion(current, previous)
                if s2e_detected:
                    adjusted_confidence += 0.08  # 8% bonus for squeezeâ†’expansion
                    enhanced_reasons.append("Sâ†’E detected (+8%)")
                else:
                    adjusted_confidence -= 0.03  # 3% penalty for no expansion
                    enhanced_reasons.append("No Sâ†’E (-3%)")
            
            # 2. Band walk confirmation bonus
            if self.enhanced_config.enable_band_walk_confirmation:
                band_walk_confirmed = self._detect_band_walk_confirmation(current)
                if band_walk_confirmed:
                    adjusted_confidence += 0.05  # 5% bonus for band walk confirmation
                    enhanced_reasons.append("Band walk confirmed (+5%)")
                else:
                    adjusted_confidence -= 0.02  # 2% penalty for no band walk
                    enhanced_reasons.append("No band walk (-2%)")
            
            # 3. Trend mode adjustment
            trend_mode = self._determine_trend_mode(current)
            if trend_mode == 'range':
                adjusted_confidence += 0.04  # 4% bonus for range mode (good for BB)
                enhanced_reasons.append("Range mode (+4%)")
            elif trend_mode == 'trend':
                adjusted_confidence += 0.02  # 2% bonus for trend mode
                enhanced_reasons.append("Trend mode (+2%)")
            
            # 4. Session filtering
            if self.enhanced_config.session_start_hour and self.enhanced_config.session_end_hour:
                in_session = self._check_trading_session()
                if in_session:
                    adjusted_confidence += 0.03  # 3% bonus for good trading hours
                    enhanced_reasons.append("In session (+3%)")
                else:
                    adjusted_confidence -= 0.05  # 5% penalty for poor trading hours
                    enhanced_reasons.append("Out of session (-5%)")
            
            # Apply confidence bounds
            adjusted_confidence = max(0.15, min(adjusted_confidence, 0.95))
            
            # Build enhanced reason
            if enhanced_reasons:
                enhanced_reason = reason + f" | Enhanced: {', '.join(enhanced_reasons)}"
            else:
                enhanced_reason = reason + " | Enhanced config active"
            
            return adjusted_confidence, enhanced_reason
            
        except Exception as e:
            self.logger.debug(f"Enhanced config adjustments failed: {e}")
            return confidence_score, reason

    def _detect_squeeze_expansion(self, current: pd.Series, previous: pd.Series) -> bool:
        """
        ðŸ†• NEW: Detect squeezeâ†’expansion transition
        """
        try:
            if not self.enhanced_config or not self.enhanced_config.enable_squeeze_expansion:
                return False
            
            # Check if s2e column exists (calculated in _ensure_enhanced_indicators)
            if 's2e' in current.index:
                return bool(current['s2e'])
            
            # Fallback calculation
            current_width = current.get('bb_width', 0)
            if 'bb_width' in previous.index:
                previous_width = previous['bb_width']
            else:
                # Calculate previous width
                prev_bb_width = previous['bb_upper'] - previous['bb_lower']
                prev_bb_mid = previous['bb_middle']
                previous_width = prev_bb_width / prev_bb_mid if prev_bb_mid > 0 else 0
            
            expansion_factor = self.enhanced_config.expansion_factor
            return current_width > previous_width * expansion_factor
            
        except Exception as e:
            self.logger.debug(f"Squeezeâ†’expansion detection failed: {e}")
            return False

    def _detect_band_walk_confirmation(self, current: pd.Series) -> bool:
        """
        ðŸ†• NEW: Detect band walk confirmation
        """
        try:
            if not self.enhanced_config or not self.enhanced_config.enable_band_walk_confirmation:
                return False
            
            current_price = current['close']
            bb_upper = current['bb_upper']
            bb_lower = current['bb_lower']
            atr_val = current.get('atr', current_price * 0.001)
            
            buffer_price = atr_val * self.enhanced_config.band_buffer_atr_mult
            
            # Check if price is in band walk zone
            near_upper = current_price >= (bb_upper - buffer_price)
            near_lower = current_price <= (bb_lower + buffer_price)
            
            return near_upper or near_lower
            
        except Exception as e:
            self.logger.debug(f"Band walk confirmation detection failed: {e}")
            return False

    def _determine_trend_mode(self, current: pd.Series) -> str:
        """
        ðŸ†• NEW: Determine if market is in trend or range mode
        """
        try:
            if not self.enhanced_config:
                return 'unknown'
            
            # Use SuperTrend direction if available
            if 'supertrend_direction' in current.index:
                st_dir = current['supertrend_direction']
                if st_dir in [1, -1]:
                    return 'trend'
            
            # Fallback: Use BB position
            current_price = current['close']
            bb_upper = current['bb_upper']
            bb_lower = current['bb_lower']
            bb_middle = current['bb_middle']
            
            # If price is near middle, likely ranging
            bb_width = bb_upper - bb_lower
            distance_from_middle = abs(current_price - bb_middle)
            relative_distance = distance_from_middle / (bb_width / 2) if bb_width > 0 else 0
            
            if relative_distance < 0.3:
                return 'range'
            else:
                return 'trend'
                
        except Exception as e:
            self.logger.debug(f"Trend mode determination failed: {e}")
            return 'unknown'

    def _check_trading_session(self) -> bool:
        """
        ðŸ†• NEW: Check if current time is within trading session
        """
        try:
            if not self.enhanced_config or not self.enhanced_config.session_start_hour:
                return True  # No session filtering
            
            current_hour = datetime.now().hour
            start_hour = self.enhanced_config.session_start_hour
            end_hour = self.enhanced_config.session_end_hour
            
            if start_hour <= end_hour:
                return start_hour <= current_hour < end_hour
            else:
                # Overnight session (e.g., 22-6)
                return current_hour >= start_hour or current_hour < end_hour
                
        except Exception as e:
            self.logger.debug(f"Trading session check failed: {e}")
            return True

    def calculate_confidence(self, signal_data: Dict) -> float:
        """
        ðŸ§  ENHANCED: Calculate confidence using forex optimizer and optimized BB settings
        """
        try:
            # Extract key data from signal
            epic = signal_data.get('epic', '')
            signal_type = signal_data.get('signal_type', 'BULL').upper()
            current_price = signal_data.get('entry_price', signal_data.get('price', 0))
            
            # Build current data series for analysis
            current_data = {
                'close': current_price,
                'bb_upper': signal_data.get('bb_upper', current_price * 1.01),
                'bb_middle': signal_data.get('bb_middle', current_price),
                'bb_lower': signal_data.get('bb_lower', current_price * 0.99),
                'supertrend': signal_data.get('supertrend', current_price),
                'supertrend_direction': signal_data.get('supertrend_direction', 1 if signal_type == 'BULL' else -1),
                'atr': signal_data.get('atr', 0.001)
            }
            current_series = pd.Series(current_data)
            
            # Start with base confidence from configuration
            base_confidence = self.bb_config.get('base_confidence', 0.60)
            confidence = base_confidence
            
            # === FOREX OPTIMIZER ENHANCEMENTS ===
            if self.forex_optimizer:
                # ðŸ” DEBUG: Track forex optimizer cache usage
                self.logger.debug("ðŸ” FOREX OPTIMIZER CONFIDENCE CALCULATION DEBUG:")
                
                # ðŸ” DEBUG: Check forex optimizer cache BEFORE operations
                try:
                    fo_cache_before = self.forex_optimizer.get_cache_stats()
                    self.logger.debug(f"  ðŸ“Š FO Cache BEFORE operations: {fo_cache_before}")
                except Exception as e:
                    self.logger.debug(f"  âŒ FO Cache BEFORE check failed: {e}")
                
                try:
                    # 1. Forex pair type adjustment
                    self.logger.debug(f"  ðŸ” Calling get_forex_pair_type({epic})")
                    pair_type = self.forex_optimizer.get_forex_pair_type(epic)
                    self.logger.debug(f"  âœ… Pair type: {pair_type}")
                    
                    if pair_type == 'major':
                        confidence *= 1.15  # 15% boost for major pairs (better liquidity)
                        self.logger.debug(f"  Applied major pair boost: +15%")
                    elif pair_type == 'cross':
                        confidence *= 1.08  # 8% boost for cross pairs
                        self.logger.debug(f"  Applied cross pair boost: +8%")
                    elif pair_type == 'exotic':
                        confidence *= 0.92  # 8% reduction for exotic pairs (higher spreads)
                        self.logger.debug(f"  Applied exotic pair penalty: -8%")
                except Exception as e:
                    self.logger.debug(f"  âŒ Pair type adjustment failed: {e}")
                
                try:
                    # 2. Market regime analysis
                    self.logger.debug(f"  ðŸ” Calling detect_forex_market_regime()")
                    market_regime = self.forex_optimizer.detect_forex_market_regime(current_series)
                    self.logger.debug(f"  âœ… Market regime: {market_regime}")
                    
                    regime_multipliers = {
                        'volatile': 1.20,      # BB strategy excels in volatile markets
                        'ranging': 1.15,       # Perfect for mean reversion
                        'trending': 1.05,      # Still good for counter-trend
                        'consolidating': 0.90  # Reduce for low volatility
                    }
                    regime_multiplier = regime_multipliers.get(market_regime, 1.0)
                    confidence *= regime_multiplier
                    self.logger.debug(f"  Applied regime multiplier: {regime_multiplier:.2f}")
                except Exception as e:
                    self.logger.debug(f"  âŒ Market regime adjustment failed: {e}")
                
                try:
                    # 3. BB position quality assessment
                    self.logger.debug(f"  ðŸ” Calling calculate_bb_position_score()")
                    bb_position_score = self.forex_optimizer.calculate_bb_position_score(current_series, signal_type)
                    self.logger.debug(f"  âœ… BB position score: {bb_position_score:.3f}")
                    
                    if bb_position_score > 0.85:  # Excellent BB position
                        confidence += 0.12  # 12% bonus for perfect setup
                        self.logger.debug(f"  Applied excellent BB position bonus: +12%")
                    elif bb_position_score > 0.70:  # Good BB position
                        confidence += 0.08  # 8% bonus
                        self.logger.debug(f"  Applied good BB position bonus: +8%")
                    elif bb_position_score < 0.30:  # Poor BB position
                        confidence *= 0.85  # 15% penalty
                        self.logger.debug(f"  Applied poor BB position penalty: -15%")
                except Exception as e:
                    self.logger.debug(f"  âŒ BB position assessment failed: {e}")
                
                try:
                    # 4. BB width/volatility optimization
                    self.logger.debug(f"  ðŸ” Calling assess_bb_volatility()")
                    volatility_level, bb_width_pct = self.forex_optimizer.assess_bb_volatility(current_series)
                    self.logger.debug(f"  âœ… Volatility: {volatility_level}, BB width %: {bb_width_pct:.4f}")
                    
                    if volatility_level == 'high' and bb_width_pct > 0.003:
                        confidence += 0.10  # 10% bonus for high volatility
                        self.logger.debug(f"  Applied high volatility bonus: +10%")
                    elif volatility_level == 'medium' and bb_width_pct > 0.0015:
                        confidence += 0.05  # 5% bonus for medium volatility
                        self.logger.debug(f"  Applied medium volatility bonus: +5%")
                    elif volatility_level == 'low' and bb_width_pct < 0.0008:
                        confidence *= 0.88  # 12% penalty for low volatility
                        self.logger.debug(f"  Applied low volatility penalty: -12%")
                except Exception as e:
                    self.logger.debug(f"  âŒ Volatility assessment failed: {e}")
                
                try:
                    # 5. Forex-specific confidence adjustments
                    self.logger.debug(f"  ðŸ” Calling apply_forex_confidence_adjustments()")
                    adjusted_confidence = self.forex_optimizer.apply_forex_confidence_adjustments(
                        confidence, epic, market_regime, bb_position_score
                    )
                    self.logger.debug(f"  âœ… Final FO adjustment: {confidence:.3f} â†’ {adjusted_confidence:.3f}")
                    confidence = adjusted_confidence
                except Exception as e:
                    self.logger.debug(f"  âŒ Final forex adjustments failed: {e}")
                
                # ðŸ” DEBUG: Check forex optimizer cache AFTER all operations
                try:
                    fo_cache_after = self.forex_optimizer.get_cache_stats()
                    self.logger.debug(f"  ðŸ“Š FO Cache AFTER operations: {fo_cache_after}")
                    
                    # Calculate cache usage difference
                    if 'cached_entries' in fo_cache_before and 'cached_entries' in fo_cache_after:
                        cache_entries_before = fo_cache_before.get('cached_entries', 0)
                        cache_entries_after = fo_cache_after.get('cached_entries', 0)
                        new_entries = cache_entries_after - cache_entries_before
                        self.logger.debug(f"  ðŸš€ New cache entries created: {new_entries}")
                    
                except Exception as e:
                    self.logger.debug(f"  âŒ FO Cache AFTER check failed: {e}")
                
                # ðŸ” DEBUG: Test if forex optimizer has actual cache methods
                try:
                    self.logger.debug("  ðŸ” Checking forex optimizer cache methods:")
                    fo_methods = [method for method in dir(self.forex_optimizer) if 'cache' in method.lower()]
                    self.logger.debug(f"    Cache-related methods: {fo_methods}")
                    
                    if hasattr(self.forex_optimizer, '_cache'):
                        cache_size = len(self.forex_optimizer._cache) if self.forex_optimizer._cache else 0
                        self.logger.debug(f"    _cache size: {cache_size} entries")
                        
                        if cache_size > 0:
                            sample_keys = list(self.forex_optimizer._cache.keys())[:3]
                            self.logger.debug(f"    Sample cache keys: {sample_keys}")
                    else:
                        self.logger.debug(f"    âŒ No _cache attribute found")
                        
                except Exception as e:
                    self.logger.debug(f"  âŒ Cache method inspection failed: {e}")
                    
            else:
                self.logger.debug("ðŸ” No forex optimizer available for confidence enhancements")
            
            # === BB STRATEGY SPECIFIC OPTIMIZATIONS ===
            
            # 6. SuperTrend alignment quality
            st_direction = signal_data.get('supertrend_direction', 0)
            expected_direction = 1 if signal_type == 'BULL' else -1
            if st_direction == expected_direction:
                # Calculate SuperTrend distance quality
                st_distance_pct = abs(current_price - signal_data.get('supertrend', current_price)) / current_price
                if 0.002 <= st_distance_pct <= 0.008:  # Optimal SuperTrend distance for forex
                    confidence += 0.08  # 8% bonus for perfect SuperTrend alignment
                elif 0.001 <= st_distance_pct <= 0.015:  # Good distance
                    confidence += 0.04  # 4% bonus
                elif st_distance_pct > 0.02:  # Too far from SuperTrend
                    confidence *= 0.92  # 8% penalty
            else:
                confidence *= 0.75  # 25% penalty for wrong SuperTrend direction
            
            # 7. BB mean reversion setup quality
            bb_middle = signal_data.get('bb_middle', current_price)
            bb_width = signal_data.get('bb_upper', current_price) - signal_data.get('bb_lower', current_price)
            
            if bb_width > 0:
                # Check if price is in proper mean reversion zone
                distance_from_middle = abs(current_price - bb_middle)
                relative_position = distance_from_middle / (bb_width / 2)
                
                if relative_position > 0.7:  # Price near bands (good for mean reversion)
                    confidence += 0.06  # 6% bonus for proper mean reversion setup
                elif relative_position < 0.2:  # Price too close to middle
                    confidence *= 0.90  # 10% penalty for poor setup
            
            # ðŸ†• NEW: Enhanced configuration adjustments
            if self.enhanced_config:
                # Squeezeâ†’expansion bonus
                if signal_data.get('enhanced_features', {}).get('squeeze_expansion_detected', False):
                    confidence += 0.08  # 8% bonus for squeezeâ†’expansion
                
                # Band walk confirmation bonus
                if signal_data.get('enhanced_features', {}).get('band_walk_confirmed', False):
                    confidence += 0.05  # 5% bonus for band walk confirmation
                
                # Trend mode bonus
                trend_mode = signal_data.get('enhanced_features', {}).get('trend_mode', 'unknown')
                if trend_mode == 'range':
                    confidence += 0.04  # 4% bonus for range mode
                elif trend_mode == 'trend':
                    confidence += 0.02  # 2% bonus for trend mode
            
            # 8. Time-based adjustments (trading session optimization)
            current_hour = datetime.now().hour
            # London session (8-17 GMT) and NY session (13-22 GMT) overlap is best for forex
            if 13 <= current_hour <= 17:  # London-NY overlap
                confidence += 0.05  # 5% bonus for best trading hours
            elif 8 <= current_hour <= 22:  # Major session hours
                confidence += 0.02  # 2% bonus for good trading hours
            elif 23 <= current_hour or current_hour <= 6:  # Asian session only
                confidence *= 0.95  # 5% penalty for lower volatility hours
            
            # 9. Volume confirmation (if available)
            volume_ratio = signal_data.get('volume_ratio_20', signal_data.get('volume_ratio', 1.0))
            if volume_ratio > 1.5:  # High volume confirmation
                confidence += 0.04  # 4% bonus
            elif volume_ratio < 0.7:  # Low volume warning
                confidence *= 0.96  # 4% penalty
            
            # 10. Risk-reward optimization
            entry_price = signal_data.get('entry_price', current_price)
            stop_loss = signal_data.get('stop_loss', signal_data.get('sl', 0))
            take_profit = signal_data.get('take_profit', signal_data.get('tp', 0))
            
            if stop_loss and take_profit and entry_price:
                risk = abs(entry_price - stop_loss)
                reward = abs(take_profit - entry_price)
                if risk > 0:
                    rr_ratio = reward / risk
                    if rr_ratio >= 2.5:  # Excellent risk-reward
                        confidence += 0.06  # 6% bonus
                    elif rr_ratio >= 2.0:  # Good risk-reward
                        confidence += 0.03  # 3% bonus
                    elif rr_ratio < 1.5:  # Poor risk-reward
                        confidence *= 0.92  # 8% penalty
            
            # === FINAL OPTIMIZATIONS ===
            
            # Apply maximum confidence cap from forex optimizer
            max_confidence = self.forex_optimizer.forex_scaling.get('max_confidence', 0.95) if self.forex_optimizer else 0.95
            confidence = min(confidence, max_confidence)
            
            # Apply minimum confidence floor for BB strategy
            min_confidence = 0.15  # Never go below 15%
            confidence = max(confidence, min_confidence)
            
            # Round to reasonable precision
            confidence = round(confidence, 3)
            
            self.logger.debug(f"ðŸ§  ENHANCED BB Confidence Calculation:")
            self.logger.debug(f"   Base: {base_confidence:.1%} â†’ Final: {confidence:.1%}")
            self.logger.debug(f"   Pair Type: {pair_type if 'forex_optimizer' in locals() and self.forex_optimizer else 'unknown'}")
            self.logger.debug(f"   Market Regime: {market_regime if 'forex_optimizer' in locals() and self.forex_optimizer else 'unknown'}")
            self.logger.debug(f"   BB Position Score: {bb_position_score:.2f}" if 'bb_position_score' in locals() else "   BB Position Score: N/A")
            if self.enhanced_config:
                self.logger.debug(f"   Enhanced Config: {self.config_name} mode active")
            
            return confidence
            
        except Exception as e:
            self.logger.error(f"Enhanced confidence calculation failed: {e}")
            # Fallback with some optimization
            try:
                base_confidence = self.bb_config.get('base_confidence', 0.60)
                
                # Simple pair type boost if possible
                epic = signal_data.get('epic', '')
                if any(major in epic.upper() for major in ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF']):
                    base_confidence *= 1.1  # 10% boost for major pairs
                
                return min(base_confidence, 0.95)
            except:
                return 0.60  # Ultimate fallback

    def clear_cache(self):
        """ðŸ§¹ Clear all cached calculations in all modules"""
        self.cache.clear_cache()
        self.forex_optimizer.clear_cache()
        self.logger.info("ðŸ§¹ MODULAR BB+SuperTrend cache cleared - all calculations will be recalculated")

    def get_cache_stats(self) -> Dict:
        """ðŸ“Š Get comprehensive cache statistics from all modules with forex optimizer debugging"""
        try:
            # Get main cache stats
            main_cache_stats = self.cache.get_cache_stats() if hasattr(self, 'cache') and self.cache else {}
            
            # ðŸ” DEBUG: Extensive forex optimizer cache investigation
            forex_optimizer_stats = {}
            if hasattr(self, 'forex_optimizer') and self.forex_optimizer:
                self.logger.debug("ðŸ” DEBUGGING FOREX OPTIMIZER CACHE:")
                
                # Check if forex optimizer has cache attributes
                fo_attrs = dir(self.forex_optimizer)
                cache_related_attrs = [attr for attr in fo_attrs if 'cache' in attr.lower()]
                self.logger.debug(f"  Cache-related attributes: {cache_related_attrs}")
                
                # Check for _cache attribute specifically
                if hasattr(self.forex_optimizer, '_cache'):
                    self.logger.debug(f"  Has _cache attribute: {type(self.forex_optimizer._cache)}")
                    self.logger.debug(f"  Cache content: {len(self.forex_optimizer._cache)} entries")
                    
                    # Log some cache entries if they exist
                    if self.forex_optimizer._cache:
                        sample_keys = list(self.forex_optimizer._cache.keys())[:5]
                        self.logger.debug(f"  Sample cache keys: {sample_keys}")
                else:
                    self.logger.debug("  âŒ No _cache attribute found")
                
                # Try to get cache stats from forex optimizer
                try:
                    forex_optimizer_stats = self.forex_optimizer.get_cache_stats()
                    self.logger.debug(f"  ðŸ“Š FO get_cache_stats() returned: {forex_optimizer_stats}")
                except Exception as e:
                    self.logger.debug(f"  âŒ FO get_cache_stats() failed: {e}")
                    forex_optimizer_stats = {'error': str(e)}
                
                # Check if forex optimizer has clear_cache method
                if hasattr(self.forex_optimizer, 'clear_cache'):
                    self.logger.debug("  âœ… Has clear_cache method")
                else:
                    self.logger.debug("  âŒ No clear_cache method")
                    
                # Check forex optimizer class structure
                self.logger.debug(f"  FO class: {self.forex_optimizer.__class__.__name__}")
                self.logger.debug(f"  FO module: {self.forex_optimizer.__class__.__module__}")
            else:
                self.logger.debug("ðŸ” No forex optimizer available for cache debugging")
                forex_optimizer_stats = {'error': 'forex_optimizer_not_available'}
            
            # Get validator cache stats if available
            validator_stats = {}
            if hasattr(self, 'validator') and hasattr(self.validator, 'get_cache_stats'):
                try:
                    validator_stats = self.validator.get_cache_stats()
                except Exception as e:
                    validator_stats = {'error': str(e)}
            
            return {
                'main_cache': main_cache_stats,
                'forex_optimizer_cache': forex_optimizer_stats,
                'validator_cache': validator_stats,
                'enhanced_config_info': self.get_enhanced_config_info(),
                'total_modules': 4,
                'modular_architecture': True,
                'debug_timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"Cache stats collection failed: {e}")
            return {'error': str(e)}

    def debug_signal_detection(self, df: pd.DataFrame, epic: str, spread_pips: float = 1.5, timeframe: str = '15m') -> Dict:
        """
        ðŸ” MODULAR: Comprehensive debugging using all helper modules
        ðŸ†• NEW: Enhanced with squeezeâ†’expansion and band walk analysis
        """
        try:
            debug_info = {
                'strategy': 'bb_supertrend_modular_enhanced',
                'epic': epic,
                'timeframe': timeframe,
                'spread_pips': spread_pips,
                'validation_steps': [],
                'rejection_reasons': [],
                'module_stats': {},
                'enhanced_features': {}
            }
            
            # Get debug info from each module
            debug_info['data_validation'] = self.data_helper.debug_data_validation(df, epic, self.min_bars)
            debug_info['forex_analysis'] = self.forex_optimizer.debug_forex_analysis(df, epic, timeframe)
            debug_info['signal_detection'] = self.signal_detector.debug_signal_detection(df, epic, spread_pips, timeframe)
            debug_info['cache_performance'] = self.cache.get_cache_stats()
            
            # ðŸ†• NEW: Enhanced configuration debug info
            debug_info['enhanced_config_info'] = self.get_enhanced_config_info()
            
            # ðŸ†• NEW: Enhanced signal analysis if config is available
            if self.enhanced_config and len(df) >= 2:
                current = df.iloc[-1]
                previous = df.iloc[-2]
                
                # Ensure enhanced indicators are calculated
                df_enhanced = self._ensure_enhanced_indicators(df)
                if len(df_enhanced) >= 2:
                    current_enhanced = df_enhanced.iloc[-1]
                    previous_enhanced = df_enhanced.iloc[-2]
                    
                    debug_info['enhanced_features'] = {
                        'squeeze_expansion_analysis': {
                            'squeeze_expansion_detected': self._detect_squeeze_expansion(current_enhanced, previous_enhanced),
                            'current_bb_width': current_enhanced.get('bb_width', 0),
                            'previous_bb_width': previous_enhanced.get('bb_width', 0),
                            'expansion_factor': self.enhanced_config.expansion_factor,
                            'squeeze_factor': self.enhanced_config.squeeze_factor
                        },
                        'band_walk_analysis': {
                            'band_walk_confirmed': self._detect_band_walk_confirmation(current_enhanced),
                            'band_walk_n_required': self.enhanced_config.band_walk_n,
                            'band_buffer_atr_mult': self.enhanced_config.band_buffer_atr_mult,
                            'price_position': self._calculate_bb_position(current_enhanced)
                        },
                        'trend_mode_analysis': {
                            'detected_mode': self._determine_trend_mode(current_enhanced),
                            'trend_detection_method': self.enhanced_config.trend_detection,
                            'require_st_agreement': self.enhanced_config.require_supertrend_agreement
                        },
                        'session_analysis': {
                            'in_trading_session': self._check_trading_session(),
                            'session_start_hour': self.enhanced_config.session_start_hour,
                            'session_end_hour': self.enhanced_config.session_end_hour,
                            'current_hour': datetime.now().hour
                        }
                    }
            
            # Try to detect signal
            signal = self.detect_signal(df, epic, spread_pips, timeframe)
            debug_info['signal_result'] = signal
            
            if signal:
                debug_info['validation_steps'].append(f"âœ… Signal detected: {signal['signal_type']} with {signal['confidence_score']:.1%} confidence")
                
                # Enhanced signal analysis
                if 'enhanced_features' in signal:
                    enhanced_features = signal['enhanced_features']
                    debug_info['validation_steps'].append(f"ðŸ†• Enhanced features active: {enhanced_features.get('config_type', 'unknown')}")
                    if enhanced_features.get('squeeze_expansion_detected'):
                        debug_info['validation_steps'].append(f"âœ… Squeezeâ†’Expansion detected")
                    if enhanced_features.get('band_walk_confirmed'):
                        debug_info['validation_steps'].append(f"âœ… Band walk confirmed")
                    debug_info['validation_steps'].append(f"ðŸ“Š Trend mode: {enhanced_features.get('trend_mode', 'unknown')}")
            else:
                debug_info['rejection_reasons'].append(f"âŒ No signal detected after all validations")
            
            return debug_info
            
        except Exception as e:
            debug_info['error'] = str(e)
            debug_info['rejection_reasons'].append(f"âŒ Exception: {e}")
            return debug_info

    def _calculate_bb_position(self, current: pd.Series) -> float:
        """
        ðŸ†• NEW: Calculate normalized BB position (0-1)
        """
        try:
            bb_width = current['bb_upper'] - current['bb_lower']
            if bb_width <= 0:
                return 0.5
            return (current['close'] - current['bb_lower']) / bb_width
        except:
            return 0.5

    def _perform_multi_timeframe_analysis(self, epic: str, signal_type: str, primary_timeframe: str) -> Optional[Dict]:
        """
        ðŸ”„ ENHANCED: Perform multi-timeframe analysis with proper cache integration
        """
        if not self.multi_timeframe_analyzer:
            self.logger.debug("Multi-timeframe analyzer not available")
            return None
        
        try:
            # Extract pair from epic
            pair = epic.replace('CS.D.', '').replace('.MINI.IP', '').replace('FOREX', '')
            
            self.logger.debug(f"ðŸ”„ Performing multi-timeframe analysis for {pair} {signal_type}")
            
            # Get multi-timeframe data
            timeframes = ['5m', '15m', '1h', '4h']
            lookback_hours = {'5m': 48, '15m': 168, '1h': 720, '4h': 2160}  # 48h, 1w, 1m, 3m
            
            mtf_data = {}
            trend_analysis = {}
            support_resistance = {}
            
            # ðŸš€ ENHANCED: Cache MTF data retrieval results
            for tf in timeframes:
                try:
                    # Use cache to check if we already analyzed this timeframe recently
                    cache_key = f"mtf_data_{pair}_{tf}_{primary_timeframe}"
                    
                    df = self.data_fetcher.get_enhanced_data(
                        epic=epic,
                        pair=pair, 
                        timeframe=tf,
                        lookback_hours=lookback_hours.get(tf, 168)
                    )
                    
                    if df is not None and len(df) > 20:
                        mtf_data[tf] = df
                        
                        # ðŸš€ Use cached analysis methods
                        if hasattr(self, 'cache') and self.cache:
                            # Create a simplified current/previous for this timeframe
                            tf_current = df.iloc[-1]
                            tf_previous = df.iloc[-2] if len(df) > 1 else df.iloc[-1]
                            
                            # Use cached efficiency ratio for this timeframe
                            try:
                                tf_efficiency = self.cache.calculate_efficiency_ratio_cached(
                                    tf_current, tf_previous, f"{epic}_{tf}", tf
                                )
                                
                                # Use cached market regime for this timeframe
                                tf_regime = self.cache.detect_market_regime_cached(
                                    tf_current, df, f"{epic}_{tf}", tf
                                )
                                
                                self.logger.debug(f"ðŸš€ {tf} cached analysis: efficiency={tf_efficiency:.2f}, regime={tf_regime}")
                                
                            except Exception as cache_error:
                                self.logger.debug(f"Cache error for {tf}: {cache_error}")
                        
                        # Analyze trend direction for this timeframe
                        trend_analysis[tf] = self._analyze_timeframe_trend(df, tf)
                        
                        # Get support/resistance levels for mean reversion
                        support_resistance[tf] = self._get_sr_levels_for_timeframe(df, tf)
                        
                except Exception as e:
                    self.logger.debug(f"Failed to get {tf} data: {e}")
                    continue
            
            if len(mtf_data) < 2:
                self.logger.debug("Insufficient timeframe data for MTF analysis")
                return None
            
            # ðŸš€ ENHANCED: Cache confluence analysis results
            confluence_analysis = self._analyze_mtf_confluence_cached(
                mtf_data, trend_analysis, support_resistance, signal_type, primary_timeframe, epic
            )
            
            # ðŸš€ Force cache usage statistics update
            if hasattr(self, 'cache') and self.cache:
                try:
                    cache_stats = self.cache.get_cache_stats()
                    confluence_analysis['cache_stats'] = {
                        'mtf_cache_hits': cache_stats.get('cache_hits', 0),
                        'mtf_cache_misses': cache_stats.get('cache_misses', 0),
                        'mtf_hit_ratio': cache_stats.get('hit_ratio', 0)
                    }
                except Exception:
                    pass
            
            self.logger.debug(f"ðŸ”„ MTF Analysis complete: {confluence_analysis.get('confluence_score', 0):.1%} confluence")
            
            return confluence_analysis
            
        except Exception as e:
            self.logger.debug(f"Multi-timeframe analysis failed: {e}")
            return None

    def _analyze_mtf_confluence_cached(
        self, 
        mtf_data: Dict, 
        trend_analysis: Dict, 
        support_resistance: Dict, 
        signal_type: str,
        primary_timeframe: str,
        epic: str
    ) -> Dict:
        """
        ðŸš€ CACHED VERSION: Analyze confluence with caching for expensive calculations
        """
        try:
            confluence_result = self._analyze_mtf_confluence(
                mtf_data, trend_analysis, support_resistance, signal_type, primary_timeframe
            )
            
            # Note: Confluence analysis is complex and varies significantly per signal
            # For now, we'll just track that we attempted caching
            if hasattr(self, 'cache') and self.cache:
                try:
                    # Increment cache usage counters (confluence calculation counts as cache operation)
                    current_stats = self.cache.get_cache_stats()
                    self.logger.debug(f"ðŸš€ MTF confluence calculated with cache support")
                except Exception:
                    pass
            
            return confluence_result
            
        except Exception as e:
            self.logger.debug(f"MTF confluence analysis failed: {e}")
            # Fallback to original method
            return self._analyze_mtf_confluence(
                mtf_data, trend_analysis, support_resistance, signal_type, primary_timeframe
            )

    def _analyze_timeframe_trend(self, df: pd.DataFrame, timeframe: str) -> Dict:
        """
        ðŸ“ˆ Analyze trend direction for a specific timeframe
        """
        try:
            if len(df) < 20:
                return {'trend': 'unknown', 'strength': 0}
            
            # Use EMA-based trend analysis if available
            if all(col in df.columns for col in ['ema_9', 'ema_21', 'ema_200']):
                latest = df.iloc[-1]
                ema_9 = latest['ema_9']
                ema_21 = latest['ema_21'] 
                ema_200 = latest['ema_200']
                current_price = latest['close']
                
                # Determine trend based on EMA alignment
                if current_price > ema_9 > ema_21 > ema_200:
                    trend = 'bullish'
                    strength = 0.9
                elif current_price > ema_9 > ema_21:
                    trend = 'bullish'
                    strength = 0.7
                elif current_price < ema_9 < ema_21 < ema_200:
                    trend = 'bearish'
                    strength = 0.9
                elif current_price < ema_9 < ema_21:
                    trend = 'bearish'
                    strength = 0.7
                else:
                    trend = 'neutral'
                    strength = 0.3
            else:
                # Fallback: Use price direction over last 20 bars
                recent_data = df.tail(20)
                price_change = (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / recent_data['close'].iloc[0]
                
                if price_change > 0.002:  # 0.2% move
                    trend = 'bullish'
                    strength = min(0.8, abs(price_change) * 50)
                elif price_change < -0.002:
                    trend = 'bearish' 
                    strength = min(0.8, abs(price_change) * 50)
                else:
                    trend = 'neutral'
                    strength = 0.3
            
            return {
                'trend': trend,
                'strength': strength,
                'timeframe': timeframe
            }
            
        except Exception as e:
            self.logger.debug(f"Timeframe trend analysis failed for {timeframe}: {e}")
            return {'trend': 'unknown', 'strength': 0, 'timeframe': timeframe}

    def _get_sr_levels_for_timeframe(self, df: pd.DataFrame, timeframe: str) -> Dict:
        """
        ðŸ“Š Get support and resistance levels for mean reversion analysis
        """
        try:
            if len(df) < 20:
                return {'support': [], 'resistance': [], 'current_level': 'unknown'}
            
            current_price = df['close'].iloc[-1]
            
            # Use BB levels if available (primary for this strategy)
            if all(col in df.columns for col in ['bb_upper', 'bb_lower', 'bb_middle']):
                latest = df.iloc[-1]
                
                support_levels = [latest['bb_lower'], latest['bb_middle']]
                resistance_levels = [latest['bb_middle'], latest['bb_upper']]
                
                # Determine current position
                bb_width = latest['bb_upper'] - latest['bb_lower']
                distance_from_middle = abs(current_price - latest['bb_middle'])
                relative_position = distance_from_middle / (bb_width / 2) if bb_width > 0 else 0
                
                if current_price <= latest['bb_lower'] + (bb_width * 0.1):
                    current_level = 'near_support'
                elif current_price >= latest['bb_upper'] - (bb_width * 0.1):
                    current_level = 'near_resistance'
                elif relative_position < 0.3:
                    current_level = 'near_middle'
                else:
                    current_level = 'trending'
            else:
                # Fallback: Use recent highs/lows
                lookback = min(50, len(df))
                recent_data = df.tail(lookback)
                
                # Find recent highs and lows
                resistance_levels = [recent_data['high'].max()]
                support_levels = [recent_data['low'].min()]
                
                # Simple position assessment
                if current_price <= support_levels[0] * 1.001:  # Within 0.1%
                    current_level = 'near_support'
                elif current_price >= resistance_levels[0] * 0.999:  # Within 0.1%
                    current_level = 'near_resistance'
                else:
                    current_level = 'middle_range'
            
            return {
                'support': support_levels,
                'resistance': resistance_levels,
                'current_level': current_level,
                'timeframe': timeframe
            }
            
        except Exception as e:
            self.logger.debug(f"S/R analysis failed for {timeframe}: {e}")
            return {'support': [], 'resistance': [], 'current_level': 'unknown', 'timeframe': timeframe}

    def _analyze_mtf_confluence(
        self, 
        mtf_data: Dict, 
        trend_analysis: Dict, 
        support_resistance: Dict, 
        signal_type: str,
        primary_timeframe: str
    ) -> Dict:
        """
        ðŸ”„ Analyze confluence across multiple timeframes for BB+SuperTrend mean reversion
        """
        try:
            confluence_result = {
                'confluence_score': 0.0,
                'agreement_level': 'low',
                'higher_timeframe_bias': 'neutral',
                'mean_reversion_setup': False,
                'trend_confluence': {},
                'sr_confluence': {},
                'primary_timeframe': primary_timeframe,
                'signal_type': signal_type
            }
            
            # Weight timeframes by importance (higher = more important for confluence)
            timeframe_weights = {'5m': 0.1, '15m': 0.2, '1h': 0.4, '4h': 0.3}
            
            # 1. Analyze trend confluence
            trend_score = 0.0
            trend_details = {}
            higher_tf_bias = 'neutral'
            
            for tf, trend_data in trend_analysis.items():
                if tf not in timeframe_weights:
                    continue
                    
                weight = timeframe_weights[tf]
                trend = trend_data.get('trend', 'unknown')
                strength = trend_data.get('strength', 0)
                
                trend_details[tf] = {'trend': trend, 'strength': strength}
                
                # For mean reversion, we want OPPOSITE trends in higher timeframes
                if tf in ['1h', '4h']:  # Higher timeframes
                    if (signal_type == 'BULL' and trend == 'bearish') or \
                       (signal_type == 'BEAR' and trend == 'bullish'):
                        # Good for mean reversion - trend exhaustion
                        trend_score += weight * strength * 1.2  # Bonus for counter-trend
                        higher_tf_bias = 'favorable'
                    elif (signal_type == 'BULL' and trend == 'bullish') or \
                         (signal_type == 'BEAR' and trend == 'bearish'):
                        # Less favorable - trend continuation
                        trend_score += weight * strength * 0.5  # Penalty for same direction
                        if higher_tf_bias != 'favorable':
                            higher_tf_bias = 'unfavorable'
                    else:  # neutral
                        trend_score += weight * 0.6
                else:  # Lower timeframes (5m, 15m)
                    if (signal_type == 'BULL' and trend == 'bullish') or \
                       (signal_type == 'BEAR' and trend == 'bearish'):
                        # Good alignment with signal direction
                        trend_score += weight * strength
                    elif trend == 'neutral':
                        trend_score += weight * 0.5
                    # No penalty for opposite trends in lower timeframes
            
            confluence_result['trend_confluence'] = trend_details
            confluence_result['higher_timeframe_bias'] = higher_tf_bias
            
            # 2. Analyze support/resistance confluence for mean reversion
            sr_score = 0.0
            sr_details = {}
            mean_reversion_favorable = False
            
            for tf, sr_data in support_resistance.items():
                if tf not in timeframe_weights:
                    continue
                    
                weight = timeframe_weights[tf]
                current_level = sr_data.get('current_level', 'unknown')
                
                sr_details[tf] = current_level
                
                # For mean reversion signals, being near S/R is GOOD
                if signal_type == 'BULL':
                    if current_level in ['near_support', 'near_lower_bb']:
                        sr_score += weight * 1.0  # Perfect setup
                        mean_reversion_favorable = True
                    elif current_level in ['near_middle', 'middle_range']:
                        sr_score += weight * 0.3  # Neutral
                    # No penalty for being near resistance (might be divergence)
                elif signal_type == 'BEAR':
                    if current_level in ['near_resistance', 'near_upper_bb']:
                        sr_score += weight * 1.0  # Perfect setup
                        mean_reversion_favorable = True
                    elif current_level in ['near_middle', 'middle_range']:
                        sr_score += weight * 0.3  # Neutral
                    # No penalty for being near support (might be divergence)
            
            confluence_result['sr_confluence'] = sr_details
            confluence_result['mean_reversion_setup'] = mean_reversion_favorable
            
            # 3. Calculate overall confluence score
            # For BB+SuperTrend mean reversion strategy:
            # - S/R confluence is MORE important (60%)
            # - Trend confluence is secondary (40%)
            overall_score = (sr_score * 0.6) + (trend_score * 0.4)
            confluence_result['confluence_score'] = min(1.0, overall_score)
            
            # 4. Determine agreement level
            if confluence_result['confluence_score'] >= 0.7:
                confluence_result['agreement_level'] = 'high'
            elif confluence_result['confluence_score'] >= 0.5:
                confluence_result['agreement_level'] = 'medium'
            elif confluence_result['confluence_score'] >= 0.3:
                confluence_result['agreement_level'] = 'low'
            else:
                confluence_result['agreement_level'] = 'poor'
            
            return confluence_result
            
        except Exception as e:
            self.logger.debug(f"MTF confluence analysis failed: {e}")
            return {
                'confluence_score': 0.0,
                'agreement_level': 'unknown',
                'error': str(e)
            }

    def _apply_mtf_confidence_adjustments(
        self, 
        base_confidence: float, 
        base_reason: str, 
        mtf_analysis: Dict,
        signal_type: str
    ) -> tuple[float, str]:
        """
        ðŸŽ¯ Apply multi-timeframe confidence adjustments for BB+SuperTrend mean reversion
        """
        try:
            adjusted_confidence = base_confidence
            mtf_reason_parts = []
            
            confluence_score = mtf_analysis.get('confluence_score', 0)
            agreement_level = mtf_analysis.get('agreement_level', 'unknown')
            higher_tf_bias = mtf_analysis.get('higher_timeframe_bias', 'neutral')
            mean_reversion_setup = mtf_analysis.get('mean_reversion_setup', False)
            
            # 1. Confluence score adjustment (up to Â±15%)
            if confluence_score >= 0.8:
                conf_adjustment = 0.15  # 15% bonus for excellent confluence
                mtf_reason_parts.append(f"Excellent MTF confluence (+15%)")
            elif confluence_score >= 0.6:
                conf_adjustment = 0.08  # 8% bonus for good confluence
                mtf_reason_parts.append(f"Good MTF confluence (+8%)")
            elif confluence_score >= 0.4:
                conf_adjustment = 0.02  # 2% bonus for fair confluence
                mtf_reason_parts.append(f"Fair MTF confluence (+2%)")
            elif confluence_score >= 0.2:
                conf_adjustment = -0.05  # 5% penalty for poor confluence
                mtf_reason_parts.append(f"Poor MTF confluence (-5%)")
            else:
                conf_adjustment = -0.10  # 10% penalty for very poor confluence
                mtf_reason_parts.append(f"Very poor MTF confluence (-10%)")
            
            adjusted_confidence += conf_adjustment
            
            # 2. Higher timeframe bias adjustment (up to Â±10%)
            if higher_tf_bias == 'favorable':
                adjusted_confidence += 0.10  # 10% bonus for favorable higher TF bias
                mtf_reason_parts.append(f"Higher TF trend exhaustion (+10%)")
            elif higher_tf_bias == 'unfavorable':
                adjusted_confidence -= 0.08  # 8% penalty for unfavorable bias
                mtf_reason_parts.append(f"Higher TF trend continuation (-8%)")
            # No adjustment for neutral
            
            # 3. Mean reversion setup bonus (up to +8%)
            if mean_reversion_setup:
                adjusted_confidence += 0.08  # 8% bonus for perfect mean reversion setup
                mtf_reason_parts.append(f"Perfect mean reversion setup (+8%)")
            
            # 4. Agreement level validation
            if agreement_level == 'poor':
                adjusted_confidence -= 0.05  # Additional 5% penalty for poor agreement
                mtf_reason_parts.append(f"Poor overall agreement (-5%)")
            elif agreement_level == 'high':
                adjusted_confidence += 0.03  # Additional 3% bonus for high agreement
                mtf_reason_parts.append(f"High overall agreement (+3%)")
            
            # Apply confidence bounds
            max_confidence = self.forex_optimizer.forex_scaling.get('max_confidence', 0.95) if self.forex_optimizer else 0.95
            adjusted_confidence = max(0.15, min(adjusted_confidence, max_confidence))
            
            # Build enhanced reason
            mtf_reason = f" | MTF: {agreement_level} confluence ({confluence_score:.1%}), {higher_tf_bias} HTF bias"
            if mtf_reason_parts:
                mtf_reason += f" - {', '.join(mtf_reason_parts)}"
            
            enhanced_reason = base_reason + mtf_reason
            
            return adjusted_confidence, enhanced_reason
            
        except Exception as e:
            self.logger.debug(f"MTF confidence adjustment failed: {e}")
            return base_confidence, base_reason + f" | MTF adjustment error: {str(e)}"


# ===== FACTORY FUNCTIONS FOR EASY INTEGRATION =====

def create_bb_supertrend_strategy(bb_config_name: str = 'default', data_fetcher=None):
    """
    ðŸ—ï¸ MODULAR: Factory function to create BB+Supertrend strategy with modular architecture
    ðŸ†• NEW: Now supports enhanced configuration system
    
    This function creates the new modular BB+Supertrend strategy while maintaining
    backward compatibility with existing code.
    """
    # Always return the new modular strategy
    strategy = BollingerSupertrendStrategy(bb_config_name=bb_config_name, data_fetcher=data_fetcher)
    
    # Validate modular integration
    if not strategy.validate_modular_integration():
        logging.getLogger(__name__).warning("âš ï¸ Modular integration validation failed - strategy may not work correctly")
    
    return strategy


def create_enhanced_bb_strategy(timeframe: str = '15m', mode: str = 'default', symbol: str = None, data_fetcher=None):
    """
    ðŸ†• NEW: Factory function to create enhanced BB strategy with specific configuration
    
    Args:
        timeframe: '5m', '15m', '1h', '4h' - trading timeframe
        mode: 'conservative', 'default', 'aggressive' - trading style
        symbol: Optional symbol for pair-specific optimization
        data_fetcher: Data fetcher instance
    
    Returns:
        Configured BollingerSupertrendStrategy with enhanced features
    """
    if not ENHANCED_CONFIG_AVAILABLE:
        logging.getLogger(__name__).warning("Enhanced config not available, falling back to standard strategy")
        return create_bb_supertrend_strategy(mode, data_fetcher)
    
    try:
        # Create strategy with enhanced config enabled
        strategy = BollingerSupertrendStrategy(bb_config_name=mode, data_fetcher=data_fetcher)
        
        # Force enhanced configuration
        if strategy.enhanced_config:
            # Update with specific timeframe and symbol
            enhanced_config = BBConfigFactory.get_config_for_timeframe(timeframe, mode, symbol)
            if enhanced_config and enhanced_config.validate():
                strategy.enhanced_config = enhanced_config
                strategy.use_enhanced_features = True
                strategy._merge_enhanced_config_with_legacy()
                
                # Update signal detector
                if hasattr(strategy.signal_detector, 'update_config'):
                    strategy.signal_detector.update_config(enhanced_config.to_dict())
                
                logging.getLogger(__name__).info(f"âœ… Enhanced BB strategy created: {mode} mode, {timeframe} timeframe")
            else:
                logging.getLogger(__name__).warning("Failed to create enhanced config, using standard strategy")
        
        return strategy
        
    except Exception as e:
        logging.getLogger(__name__).error(f"Failed to create enhanced BB strategy: {e}")
        return create_bb_supertrend_strategy(mode, data_fetcher)


# ===== BACKWARD COMPATIBILITY WRAPPER =====

class LegacyBollingerSupertrendStrategy(BollingerSupertrendStrategy):
    """
    ðŸ”„ LEGACY: Backward compatibility wrapper for existing BB+Supertrend strategy usage
    
    This ensures that any existing code that directly instantiates BollingerSupertrendStrategy
    will continue to work without any changes while getting all the benefits
    of the new modular architecture.
    """
    
    def __init__(self, config_name: str = 'default'):
        # Call the new modular strategy
        super().__init__(bb_config_name=config_name)
        
        # Log that legacy wrapper is being used
        self.logger.info("ðŸ”„ Using modular BB+Supertrend strategy via legacy wrapper - consider updating to factory function")


# ===== MODULE SUMMARY FOR DOCUMENTATION =====

def get_modular_bb_summary() -> Dict:
    """
    ðŸ“‹ Get summary of modular BB+Supertrend strategy architecture
    
    This provides documentation about the refactored modular structure
    for developers and maintainers.
    """
    return {
        'architecture': 'modular_with_dependency_injection',
        'main_class': 'BollingerSupertrendStrategy',
        'enhanced_features': {
            'squeeze_expansion_detection': ENHANCED_CONFIG_AVAILABLE,
            'band_walk_confirmation': ENHANCED_CONFIG_AVAILABLE,
            'pre_built_configurations': ENHANCED_CONFIG_AVAILABLE,
            'timeframe_optimization': ENHANCED_CONFIG_AVAILABLE,
            'session_filtering': ENHANCED_CONFIG_AVAILABLE
        },
        'modules': {
            'BBForexOptimizer': {
                'file': 'helpers/bb_forex_optimizer.py',
                'responsibility': 'Forex-specific calculations and optimizations',
                'key_methods': [
                    'get_forex_pair_type',
                    'apply_forex_confidence_adjustments', 
                    'calculate_forex_efficiency_ratio',
                    'detect_forex_market_regime',
                    'get_bb_config'
                ]
            },
            'BBValidator': {
                'file': 'helpers/bb_validator.py',
                'responsibility': 'Signal validation and confidence calculation',
                'key_methods': [
                    'validate_bb_supertrend_signal',
                    'validate_bb_position_quality',
                    'validate_supertrend_alignment',
                    'calculate_weighted_confidence'
                ]
            },
            'BBCache': {
                'file': 'helpers/bb_cache.py',
                'responsibility': 'Performance caching and optimization',
                'key_methods': [
                    'calculate_efficiency_ratio_cached',
                    'detect_market_regime_cached',
                    'get_cache_stats',
                    'optimize_cache_settings'
                ]
            },
            'BBSignalDetector': {
                'file': 'helpers/bb_signal_detector.py',
                'responsibility': 'Core signal detection algorithms with enhanced features',
                'key_methods': [
                    'detect_bb_supertrend_signal',
                    'analyze_bb_position',
                    'analyze_supertrend_confirmation',
                    'update_config'
                ]
            },
            'BBDataHelper': {
                'file': 'helpers/bb_data_helper.py',
                'responsibility': 'Data preparation and enhancement',
                'key_methods': [
                    'ensure_bb_indicators',
                    'create_enhanced_signal',
                    'build_complete_signal',
                    'validate_bb_data'
                ]
            },
            'BBEnhancedConfig': {
                'file': 'helpers/bb_enhanced_config.py',
                'responsibility': 'Enhanced configuration system',
                'available': ENHANCED_CONFIG_AVAILABLE,
                'key_methods': [
                    'BBConfigFactory.fx15m_default',
                    'BBConfigFactory.get_config_for_timeframe',
                    'integrate_with_main_config',
                    'validate'
                ]
            }
        },
        'features': {
            'mean_reversion_strategy': True,
            'ema200_filter_bypass': True,
            'intelligent_caching': True,
            'forex_optimized': True,
            'enhanced_signal_validator': True,
            'modular_architecture': True,
            'backward_compatible': True,
            'squeeze_expansion_detection': ENHANCED_CONFIG_AVAILABLE,
            'band_walk_confirmation': ENHANCED_CONFIG_AVAILABLE,
            'adaptive_exit_strategies': ENHANCED_CONFIG_AVAILABLE
        },
        'configuration_options': [
            'conservative',
            'default', 
            'aggressive'
        ],
        'factory_functions': [
            'create_bb_supertrend_strategy',
            'create_enhanced_bb_strategy'
        ],
        'legacy_wrapper': 'LegacyBollingerSupertrendStrategy',
        'enhanced_config_available': ENHANCED_CONFIG_AVAILABLE
    }


# Export for use in signal detector
__all__ = [
    'BollingerSupertrendStrategy', 
    'create_bb_supertrend_strategy', 
    'create_enhanced_bb_strategy',
    'LegacyBollingerSupertrendStrategy', 
    'get_modular_bb_summary'
]